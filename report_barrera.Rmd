---
title: "Barrera-Osorio et al 2011"
author: "Dimitrios & Eva"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 1
    number_sections: true
---

\newpage


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# packages -> double check that all these are needed.


#library(knitrBootstrap)
library(dplyr)

# reading STATA files
library(haven)
library(table1)

# lm.cluster function
library(lmtest)

library(miceadds)
library(ggplot2)
library(sandwich)

# visualise residuals for clustered regression
library(visreg)
#library(sjPlot)
#library(sjmisc)
#library(sjlabelled)

library(tidyverse)       # For ggplot, dplyr, and friends
library(broom)           # Convert model objects into data frames


```



# Motivation



##Why is this research question relevant?

Education in Colombia and other middle-income countries face challenges such as high dropout rates among low-income students, and the reasons behind them, such as the high cost of education. Conditional cash transfers (CCTs) are an evidence-based intervention to increase participation in education. However, the authors highlight that there is little variability in the structure of programmes. The paper investigates if changes in the timing of payments affect the outcomes of interest: Attendance and re-enrollment. Optimising the structure of CCTs may contribute to improved education outcomes and reduce disparities in access to education.


## What are the main hypotheses?

* The savings model will improve outcomes compared to the basic programme by relaxing possible savings constraints.
* The tertiary model will improve rates of graduation and tertiary enrollment compared to the basic programme by providing direct incentives for continuation of education.

# Data sources

We investigated performing the replication with the data provided as part of the lecture. However, we soon discovered that the file did not contain all required variables, nor was there any meta data or other information about the variables in the dataset. A brief search revealed that the data and STATA scripts used to obtain the authors' results are [freely available here](https://www.openicpsr.org/openicpsr/project/113783/version/V1/view?path=/openicpsr/113783/fcr:versions/V1/AEJApp_2010-0132_Data&type=folder).

For this project, we reference the following files:
* Data file: Public_Data_AEJApp_2010-0132.dta
* STATA script for Table 3: Table_03_Attendance.do
* Meta data: AEJApp_2010-0132_Data_ReadMe.pdf


## Where does the data come from (country, time period, source)?
Add

## What are the key variables and ow are these measured?

Add


# Method

## Research design
The research paper describes three interventions designed to improve attendance and educational outcomes for students in Colombia.

The first intervention ("basic") is similar to the PROGRESA/OPORTUNIDADES program, a conditional cash transfer program in Mexico that operated from 1997 to 2012. It pays participants 30,000 pesos per month (approximately US$15) if the child attends at least 80% of the days in that month. Payments are made bi-monthly through a dedicated debit card, and students will be removed from the program if they fail to meet attendance targets or are expelled from school.

The second intervention, called the savings treatment, pays two-thirds of the monthly amount (20,000 pesos or US$10) to students' families on a bi-monthly basis, while the remaining one-third is held in a bank account. The accumulated funds are then made available to students' families during the period in which students prepare to enroll for the next school year, with 100,000 pesos (US$50) available to them in December if they reach the attendance target every month.

The third intervention, called the tertiary treatment, incentivizes students to graduate and matriculate to a higher education institution. The monthly transfer for good attendance is reduced from 30,000 pesos per month to 20,000 pesos, but upon graduating, the student earns the right to receive a transfer of 600,000 pesos (US$300) if they enroll in a tertiary institution, and after a year if they fail to enroll upon graduation.

All payments are based on reports provided to the Secretary of Education by the students' principals. Students will be removed from the program if they fail to meet attendance targets, fail to matriculate to the next grade twice, or are expelled from school.


The eligibility criteria for the basic and savings experiments were as follows:

* Children had to have finished grade 5 and be enrolled in grades 6 - 11.
* The children's families had to be classified into the bottom two categories on Colombia's poverty index (SISBEN).
* Only households living in San Cristobal prior to 2004 were eligible to participate.

The eligibility criteria for the tertiary education experiment were as follows:

* Children had to have finished grade 8 and be enrolled in grade 9 - 11.
* The children's families had to be classified into the bottom two categories on Colombia's poverty index, the SISBEN.
* Only households living in Suba prior to 2004 were eligible to participate.

The paper investigates differences in enrollment and graduation / progression to tertiary education for the three treatment groups compared to untreated controls. Randomization to treatment vs control group was stratified by location, school public vs private, gender and grade.

## Data preparation



```{r data_prep, echo = FALSE}

# Importing STATA file

barrera <- read_dta("data/Public_Data_AEJApp_2010-0132.dta")

# Turning variables into factor variables --> is this the correct approach?

barrera$f_teneviv <- factor(barrera$s_teneviv)
barrera$f_estcivil <- factor(barrera$s_estcivil, levels = c(1, 2, 3, 4, 5), labels = c("Free union", "Married", "Widow(er)", "Divorced", "Single"))
barrera$f_estrato <- factor(barrera$s_estrato)
barrera$f_grade <- factor(barrera$grade)
barrera$f_sexo <- factor(barrera$s_sexo, levels = c(0,1), labels = c("Female", "Male"))
barrera$f_single <- factor(barrera$s_single, levels = c(0,1), labels = c("No", "Yes"))
barrera$f_over_age <- factor(barrera$s_over_age, levels = c(0,1), labels = c("No", "Yes"))
barrera$f_suba <- factor(barrera$suba, levels = c(0,1), labels = c("San Cristobal", "Suba"))




# Generate one variable to capture treatment assignment (T1, T2, control)

barrera$T1T2T3 <- case_when(
  barrera$T1_treat == 1 ~ 1,
  barrera$T2_treat == 1 ~ 2,
  barrera$T3_treat == 1 ~ 3,
  barrera$T1_treat == 0 & barrera$T2_treat == 0 & barrera$T3_treat == 0 ~ 0
)

barrera$T1T2T3 <- factor(barrera$T1T2T3, level = c(0, 1, 2, 3), labels = c("Control", "Basic (T1)", "Savings (T2)", "Tertiary (T3"))


# Filtering data in line with the following STATA code operations to reproduce table 3, columns 1-3:
# Dropping ineligible cases from Suba: Drop if suba == 1 and grade is < 9
# drop if suba == 1 & grade < 9; 
# The above seems to be a mistake in the STATA code: this should be grade < 6 instead of < 9. 
# Keeping only those who were selected for the survey:
# keep if survey_selected;
# Drop if they are in grade 11


# Filtered data

filtered_barrera <- barrera %>% filter(suba == 0, grade >= 6, survey_selected == 1, grade != 11)


# Filtering data in line with the following STATA code operations to reproduce table 3, columns 4-6:
# Same as above, but suba == 1 and in rade 9 or 10

filtered_barrera2 <- barrera %>% filter(suba == 1, survey_selected == 1, grade >= 9, grade <= 10)

```

ADD: Steps we've taken to use the data.
The dataset for our analysis is called "filtered_barrera" (put this to R-code).


##Analysis

### What are the assumptions of the method?

For Model 1: 
From ChatGPT:
Linear regression is a statistical technique used to model the relationship between a dependent variable and one or more independent variables. The assumptions about the data underlying linear regression are:

1. Linearity: There should be a linear relationship between the independent and dependent variables. This means that as the independent variable changes, the dependent variable changes proportionally.

2. Independence: The observations used in the regression analysis should be independent of each other. In other words, the value of one observation should not be influenced by the value of another observation.

3. Homoscedasticity: Homoscedasticity refers to the assumption that the variance of the dependent variable is constant across all values of the independent variable(s). This means that the spread of the residuals (the difference between the predicted value and the actual value) should be the same across all levels of the independent variable(s).

4. Normality: The dependent variable should be normally distributed at each level of the independent variable(s). This means that the residuals should be normally distributed and the distribution of the dependent variable should be symmetrical around the mean.

5. No multicollinearity: If there are multiple independent variables in the regression model, there should be no high correlation between these independent variables. This means that the independent variables should be unrelated to each other.

Violations of these assumptions can lead to biased or inefficient estimates of the regression coefficients and incorrect inferences about the relationship between the independent and dependent variables. Therefore, it is important to check these assumptions before interpreting the results of a linear regression analysis.

Fixed effect models: Used to control for unobserved factors that are constant over time at any level of analysis. The key is to identify the appropriate level of analysis for the fixed effect and include it in the model to account for the unobserved factors that affect the outcome variable. In this case, the school was chosen as the fixed effect, while standard errors are clustered within the individual.This reflects the multiple levels of clustering off effects (unobserved school characteristics and unobserved characteristics of individuals).


### Are these assumptions plausible in this example?

Assumptions of linear regression:
The authors do not discuss this.

Problem: While there are some plots built into R, a lot of these just don't work easily with clustered data.
My workaround: Plotting on the simplest model (model 1) to show that simple linear regression would not have been a good choice. But that seems very obvious.

```{r outcome_var, echo = FALSE}

# Plotting the outcome variable

ggplot(filtered_barrera, aes(x = T1T2T3, y = at_msamean)) +
  geom_boxplot() +    # Box plot for visualization
  labs(x = "Treatment", y = "Attendance %")  # Label the axes


hist(filtered_barrera$at_msamean)


# Create separate histograms of at_msamean for each level of T1T2T3
ggplot(filtered_barrera, aes(x = at_msamean)) +
  geom_histogram(binwidth = 0.07, alpha = 0.5, position = "identity") +
  labs(x = "Attendance %", y = "Frequency") +
  facet_wrap(~T1T2T3, ncol = 3) +
  geom_vline(xintercept = 0.8, color = "red", linetype = "dashed")+
  theme(panel.border = element_rect(colour = "black", fill = NA, size = 1),
        panel.spacing = unit(0.5, "lines"))

# Create separate cumulative distribution plots of at_msamean for each level of T1T2T3
ggplot(filtered_barrera, aes(x = at_msamean)) +
  stat_ecdf(aes(color = T1T2T3)) +
  labs(x = "at_msamean", y = "Cumulative Probability") +
  facet_wrap(~T1T2T3, ncol = 3) +
  geom_vline(xintercept = 0.8, color = "red", linetype = "dashed") +
  theme(panel.border = element_rect(colour = "black", fill = NA, size = 1),
        panel.spacing = unit(0.5, "lines"))

# What proportion in each group falls at or above the target of 80% attendance?

cutoff <- 0.8  # set the cutoff value

filtered_barrera %>% 
  group_by(T1T2T3) %>% 
  summarize(prop_cutoff = sum(at_msamean >= cutoff) / n())


```


### Maybe: regression equation.






# Descriptive statistics

- Describe sample



```{r table1, echo = TRUE}

# Table 1



# Using n = 5,799 to get the sample actually used in our model (for columns 1-3). Variables selected based on Table 1.
# Note: Some factor variables are presented in the paper as scale vars.

# House posessions - f_teneviv
# utilities - s_utilities
# durable goods - s_durables
# physical infrastructure - s_infraest_hh
# age - s_age_sorteo
# gender - s_sexo
# years of education - s_yrs
# single head - s_single
# Age of head - s_edadhead
# years of ed head - s_yrshead
# people in household - s_tpersona
# Member under 18 - s_num18
# estrato - f_estrato
# SISBEN - s_puntaje
# household income - s_ingtotal







table1 <- table1(~ factor(f_teneviv) + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + factor(f_sexo) + s_yrs + factor(f_single) + s_edadhead + s_yrshead + s_tpersona + s_num18 + factor(f_estrato) + s_puntaje + s_ingtotal | ~ factor(T1T2T3), data=filtered_barrera)



```

table1


```{r a, echo = FALSE}


```


# Results

- Are these results plausible?
- How robust are the results to changing the sample?

```{r models, echo = FALSE}



# Models


# Model 1

mod1 <- lm.cluster(data = filtered_barrera, at_msamean ~ T1_treat + T2_treat,  cluster = "school_code")
#mod1 <- lm(data = filtered_barrera, at_msamean ~ T1_treat + T2_treat)
summary(mod1)
#summary(mod1, cluster = "school_code")


# Model 2
mod2 <- lm.cluster(data = filtered_barrera, at_msamean ~ T1_treat + T2_treat + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age,  cluster = "school_code")
summary(mod2)



# Model 3
mod3 <- lm.cluster(data = filtered_barrera, at_msamean ~ T1_treat + T2_treat + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age + factor(school_code),  cluster = "school_code")
summary(mod3)


# # Model 4
# mod4 <- lm.cluster(data = filtered_barrera2, at_msamean ~ T3_treat,  cluster = "school_code")
# summary(mod4)
# # Model 5
# mod5 <- lm.cluster(data = filtered_barrera2, at_msamean ~ T3_treat + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age,  cluster = "school_code")
# summary(mod5)
# # Model 6
# mod6 <- lm.cluster(data = filtered_barrera2, at_msamean ~ T3_treat + + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age + factor(school_code),  cluster = "school_code")
# summary(mod6)




```



# Graph

ggplot(data=filtered_barrera, aes(x=at_baseline, y=at_msamean, color=factor(T1T2T3))) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE)


ggplot(data=filtered_barrera, aes(x=at_baseline, y=at_msamean, color=factor(T1T2T3))) +
  geom_smooth(method="lm", se=FALSE)+
  xlim(0.65, NA) +
  ylim(0.5, NA)




# Some exploration

# Part of the problem with this model is the outcome variable, which has a ceiling effect (can't go above 100%, and many people have high attendance, with target attendance also being high at 80%.)
# Alternative way of approaching this:
# GLM for skewed data (e.g. log link and gamma function --> would need to fit this more carefully, )
# Binary variable: Whether or not student achieved 80% attendance


# Calculating new column: is at or above cut-off?

filtered_barrera <- filtered_barrera %>% 
  mutate(above_cutoff = ifelse(at_msamean >= cutoff, 1, 0))

# Running above model but with this as outcome --> note that the residual plots don't pick up the clustered standard errors.
library(clusterSEs) # to get augment method for lm.cluster
library(sandwich)
library(broom) # augment for glm

mod_bi <- glm(data = filtered_barrera, above_cutoff ~ T1_treat + T2_treat + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age + factor(school_code), family = binomial())
summary(mod_bi)
vcov <- vcovCL(mod_bi, cluster = filtered_barrera$school_code)
coeftest(mod_bi, vcov = vcov)


fitted_bi <- augment(mod_bi, data = filtered_barrera, se_fit = TRUE)

plot_bi <- ggplot(fitted_bi, aes(x = .resid)) +
  geom_histogram(binwidth = 0.01, color = "white", boundary = 50000)
plot_bi

# To compare, running linear model as glm:

mod_gau <- glm(data = filtered_barrera, at_msamean ~ T1_treat + T2_treat + f_teneviv + s_utilities + s_durables + s_infraest_hh + s_age_sorteo + s_age_sorteo2 + s_years_back + s_sexo + f_estcivil + s_single + s_edadhead + s_yrshead + s_tpersona + s_num18 + f_estrato + s_puntaje + s_ingtotal + f_grade + suba + s_over_age + factor(school_code), family = gaussian())
summary(mod_gau)
vcov <- vcovCL(mod_gau, cluster = filtered_barrera$school_code)
coeftest(mod_gau, vcov = vcov)

#fitted_gau <- augment(mod_gau, data = filtered_barrera)
fitted_gau <- augment(mod_gau, data = filtered_barrera, se_fit = TRUE)


plot_gau <- ggplot(fitted_gau, aes(x = .resid)) +
  geom_histogram(binwidth = 0.01, color = "white", boundary = 50000)
plot_gau

library(gridExtra) # to show two plots next to each other - I know there is another way!
# arrange plots side by side
grid.arrange(plot_bi, plot_gau, nrow = 2)


# GLM with binary outcome variable performs much better on AIC. But I'm not sure the residual plots help us very much as it's not clustered SE!





# Conclusion

- Replication of a research paper: How do results compare to results of research paper?

Compare coefficients, standard errors
Why might they be different?
* Software: Possible to get STATA standard errors in R


```{r b, echo = FALSE}


```

Source for clustered standard errors in R: https://evalf21.classes.andrewheiss.com/example/standard-errors/





